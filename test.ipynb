{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and  document  first  is  new  one  second  the  third  this\n",
      "0    0         0      0   1    1    0       0    0      0     1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'This is the first document new',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "new_sentence = 'This is a new sentence.'\n",
    "\n",
    "new_sentence_vector = vectorizer.transform([new_sentence])\n",
    "\n",
    "dense_matrix = new_sentence_vector.toarray()\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(dense_matrix, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ani',\n",
       " 'bahira',\n",
       " 'bhaye',\n",
       " 'cha',\n",
       " 'chha',\n",
       " 'gari',\n",
       " 'hami',\n",
       " 'haru',\n",
       " 'hernu',\n",
       " 'hunu',\n",
       " 'kasari',\n",
       " 'ke',\n",
       " 'ko',\n",
       " 'lai',\n",
       " 'le',\n",
       " 'ma',\n",
       " 'mero',\n",
       " 'nai',\n",
       " 'na',\n",
       " 'pani',\n",
       " 'parne',\n",
       " 'ra',\n",
       " 'sanga',\n",
       " 'tapai',\n",
       " 'timi',\n",
       " 'unko',\n",
       " 'usko',\n",
       " 'vai',\n",
       " 'vane',\n",
       " 'yo']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"stopwords.json\", \"r\") as stopwords:\n",
    "  data = json.load(stopwords)\n",
    "\n",
    "data[\"nepali_stop_words\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
